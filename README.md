â¸»

âš™ï¸ Running the Pipeline

ğŸ›‘ Note: Due to headless browser dependencies, Playwright scripts will not run inside dev_containers. Please run them locally on your machine.

â–¶ï¸ Full Pipeline

To execute the entire scraping + SQL injection flow in the correct order:
activate venv
python scripts/orchestrator.py

This will:
	1.	Scrape missing company IDs and URLs.
	2.	Run all Playwright-based scrapers in parallel (income, balance, cashflow, profile, etc.).
	3.	Inject cleaned results into PostgreSQL via SQL scripts.

ğŸ” Run a Specific Step

To run a single script (e.g., profile_scraper.py):

python scripts/orchestrator.py --only profile_scraper.py


â¸»

Let me know if youâ€™d like the README to include .env setup steps or Docker alternatives for Playwright that bypass the dev container issue.
â¸»

ğŸ“Š Bursa Data Pipeline

This repository contains the complete data pipeline used to scrape, clean, and inject financial and profile data of publicly listed companies on Bursa Malaysia into a PostgreSQL database.

â¸»

ğŸ—‚ï¸ Project Structure

bursa_dataset_and_cleaning/
â”œâ”€â”€ list_bursa_ids/             # Source bursa_urls to gather raw company ID data
â”œâ”€â”€ scrapers_1000/              # Playwright & BeautifulSoup scrapers (income, balance, etc.)
â”œâ”€â”€ csvs/cleaned/               # Cleaned CSVs, including resolved URLs
â”œâ”€â”€ debug_html/                 # Debug HTML dumps of failed scrapes
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ bursa_scrape_sql_inject/
â”‚   â”‚   â”œâ”€â”€ bursa_data/         # Processed data (combined CSVs, cleaned full tables)
â”‚   â”‚   â”œâ”€â”€ column_percentages/ # Null ratio summaries for analysis
â”‚   â”‚   â”œâ”€â”€ mapping/            # Mapping scripts to align DB fields with scraped fields
â”‚   â”‚   â””â”€â”€ sql_scripts/        # SQL injection scripts for PostgreSQL
â”œâ”€â”€ screenshots/                # Fail screenshots per company_id


â¸»

ğŸ” Data Flow

Step 1: Company ID Collection (list_bursa_ids)
	â€¢	Parse company data from PDFs and CSVs (List_of_Companies.pdf, etc.).
	â€¢	Output a master list of companies (bursa_company_list.csv).
	â€¢	This list includes company names, IDs, and market board classification (Main, ACE, LEAP).

Step 2: URL Resolution (scrapers_1000/bursa_url_finder.py)
	â€¢	Uses Playwright to locate each companyâ€™s page on Bursa Malaysia.
	â€¢	Outputs resolved URLs to csvs/cleaned/company_urls.csv.

Step 3: Web Scraping (scrapers_1000/)
	â€¢	Uses Playwright for dynamic pages and BeautifulSoup for parsing static HTML.
	â€¢	Key scripts:
	â€¢	income_statement.py
	â€¢	balance_sheet.py
	â€¢	cash_flow.py
	â€¢	market_capscrape.py
	â€¢	profile_scraper.py
	â€¢	Extracted data is saved in both outputs/ and combined into scripts/bursa_scrape_sql_inject/bursa_data/.
	â€¢	ssm_api matching script

Step 4: SQL Injection (scripts/bursa_scrape_sql_inject/sql_scripts)
	â€¢	Transforms cleaned data into normalized formats.
	â€¢	Injects data into a PostgreSQL database using SQLAlchemy.
	â€¢	Environment variables in .env are used to connect securely.

â¸»

ğŸ§ª Technologies Used
	â€¢	Python
	â€¢	Playwright â€“ Browser automation for scraping
	â€¢	BeautifulSoup â€“ HTML parsing
	â€¢	Polars / Pandas â€“ Data processing
	â€¢	PostgreSQL â€“ Data storage
	â€¢	SQLAlchemy â€“ Python DB interface
	â€¢	tqdm â€“ Progress tracking
	â€¢	dotenv â€“ Secure credential loading

â¸»

ğŸ“¥ Output Highlights

All cleaned and combined datasets are saved under:

scripts/bursa_scrape_sql_inject/bursa_data/
â”œâ”€â”€ combined_profile.csv
â”œâ”€â”€ combined_management.csv
â”œâ”€â”€ combined_ownership.csv
â”œâ”€â”€ combined_top10.csv
â”œâ”€â”€ combined_insider.csv
â”œâ”€â”€ complete_income_statements.csv
â”œâ”€â”€ complete_balance_sheets.csv
â”œâ”€â”€ complete_cash_flow_statements.csv
â””â”€â”€ market_info_sample.csv


â¸»

ğŸ—ƒï¸ Database Tables

Examples of PostgreSQL target tables:
	â€¢	public_complete_income
	â€¢	public_complete_balance_sheet
	â€¢	public_complete_company_profile
	â€¢	public_complete_directors_executives
	â€¢	public_complete_insider

â¸»

ğŸ§¼ Quality Checks

Null ratio summaries for major datasets are saved in:

scripts/bursa_scrape_sql_inject/column_percentages/


â¸»

